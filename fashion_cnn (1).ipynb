{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nprint(torch.__version__)\nprint(torchvision.__version__)\nimport time","execution_count":2,"outputs":[{"output_type":"stream","text":"1.4.0\n0.5.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trans = []\nresize =224\ntrans.append(torchvision.transforms.Resize(size=resize))\ntrans.append(torchvision.transforms.ToTensor())\ntransforms = torchvision.transforms.Compose(trans)\n\nmnist_train = torchvision.datasets.FashionMNIST(root='/kaggle/data/FashionMNIST2065', train=True, download=True, transform=transforms)\nmnist_test = torchvision.datasets.FashionMNIST(root='/kaggle/data/FashionMNIST2065', train=False,download=True, transform=transforms)","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457444d2d98547909d1c8379298a4ca8"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/data/FashionMNIST2065/FashionMNIST/raw/train-images-idx3-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11adb18a565e4732844bdfd292d27b0b"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/data/FashionMNIST2065/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d02e08691124306bca245f1a6f66f9e"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/data/FashionMNIST2065/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afe64d1e600f4112b9112460c7ae28af"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/data/FashionMNIST2065/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/data/FashionMNIST2065/FashionMNIST/raw\nProcessing...\nDone!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(mnist_train)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"60000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#net\nclass Flatten(torch.nn.Module):  #展平操作\n    def forward(self, x):\n        return x.view(x.shape[0], -1)\n\nclass Reshape(torch.nn.Module): #将图像大小重定型\n    def forward(self, x):\n        return x.view(-1,1,28,28)      #(B x C x H x W)\n\ndef Lenet():\n    net = torch.nn.Sequential(     #Lelet                                                  \n        Reshape(),\n        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28\n        nn.Sigmoid(),                                                       \n        nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14\n        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10\n        nn.Sigmoid(),\n        nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5\n        Flatten(),                                                          #b*16*5*5   => b*400\n        nn.Linear(in_features=16*5*5, out_features=120),\n        nn.Sigmoid(),\n        nn.Linear(120, 84),\n        nn.Dropout(0.5),\n        nn.Sigmoid(),\n        nn.Linear(84, 10)\n        )\n    return net\n\ndef Alexnet():\n    net = nn.Sequential(\n            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2), # kernel_size, stride\n            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n            nn.Conv2d(96, 256, 5, 1, 2),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2),\n            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n            # 前两个卷积层后不使用池化层来减小输入的高和宽\n            nn.Conv2d(256, 384, 3, 1, 1),\n            nn.ReLU(),\n            nn.Conv2d(384, 384, 3, 1, 1),\n            nn.ReLU(),\n            nn.Conv2d(384, 256, 3, 1, 1),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2),\n            Flatten(),\n            nn.Linear(256*5*5, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n            nn.Linear(4096, 10),\n        )\n    return net\n\ndef VGG():\n    net = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n            nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n            Flatten(),\n            nn.Linear(in_features=3136, out_features=512, bias=True),\n            nn.ReLU(),\n            nn.Dropout(p=0.5, inplace=False),\n            nn.Linear(in_features=512, out_features=512, bias=True),\n            nn.ReLU(),\n            nn.Dropout(p=0.5, inplace=False),\n            nn.Linear(in_features=512, out_features=10, bias=True)\n          )\n    return net\n\ndef nin_block(in_channels, out_channels, kernel_size, stride, padding):\n    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n                        nn.ReLU(),\n                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n                        nn.ReLU(),\n                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n                        nn.ReLU())\n    return blk\nclass GlobalAvgPool2d(nn.Module):\n    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n    def __init__(self):\n        super(GlobalAvgPool2d, self).__init__()\n    def forward(self, x):\n        return nn.functional.avg_pool2d(x, kernel_size=x.size()[2:])\ndef NiN():\n    net = nn.Sequential(\n        nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n        nn.MaxPool2d(kernel_size=3, stride=2),\n        nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n        nn.MaxPool2d(kernel_size=3, stride=2),\n        nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n        nn.MaxPool2d(kernel_size=3, stride=2), \n        nn.Dropout(0.5),\n        # 标签类别数是10\n        nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n        GlobalAvgPool2d(), \n        # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n        Flatten())\n    return net\nnet = Alexnet()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size =128\ntrain_iter =  torch.utils.data.DataLoader(dataset = mnist_train, batch_size = 256, shuffle = True)\ntest_iter = torch.utils.data.DataLoader(dataset = mnist_test, batch_size = 256, shuffle = True)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function has been saved in the d2l package for future use\n#use GPU\ndef try_gpu():\n    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    else:\n        device = torch.device('cpu')\n    return device\n\ndevice = try_gpu()\ndevice","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n    for X,y in data_iter:\n        # If device is the GPU, copy the data to the GPU.\n        X,y = X.to(device),y.to(device)\n        net.eval()\n        with torch.no_grad():\n            y = y.long()\n            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n            n += y.shape[0]\n    return acc_sum.item()/n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#训练函数\ndef train_ch5(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None,weight_decay=None):\n    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n    print('training on', device)\n    net.to(device)\n    optimizer = torch.optim.Adam(params = net.parameters(), lr=lr,weight_decay = weight_decay)\n    for epoch in range(num_epochs):\n        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n        n, start = 0, time.time()\n        for X, y in train_iter:\n            net.train()\n            \n            optimizer.zero_grad()\n            X,y = X.to(device),y.to(device) \n            y_hat = net(X)\n            loss = criterion(y_hat, y)\n            loss.backward()\n            optimizer.step()\n            \n            with torch.no_grad():\n                y = y.long()\n                train_l_sum += loss.float()\n                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n                n += y.shape[0]\n        test_acc = evaluate_accuracy(test_iter, net,device)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n                 time.time() - start))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 训练\nlr, num_epochs,weight_decay = 0.001, 10,0.0001\n\ndef init_weights(m):\n    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n        torch.nn.init.xavier_uniform_(m.weight)\n\nnet.apply(init_weights)\nnet = net.to(device)\n\ncriterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\ntrain_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr,weight_decay)","execution_count":25,"outputs":[{"output_type":"stream","text":"training on cuda:0\nepoch 1, loss 0.0026, train acc 0.745, test acc 0.839, time 56.9 sec\nepoch 2, loss 0.0013, train acc 0.874, test acc 0.890, time 58.0 sec\nepoch 3, loss 0.0011, train acc 0.893, test acc 0.890, time 57.8 sec\nepoch 4, loss 0.0010, train acc 0.906, test acc 0.898, time 56.3 sec\nepoch 5, loss 0.0009, train acc 0.914, test acc 0.907, time 56.3 sec\nepoch 6, loss 0.0009, train acc 0.919, test acc 0.904, time 57.6 sec\nepoch 7, loss 0.0008, train acc 0.923, test acc 0.908, time 57.0 sec\nepoch 8, loss 0.0008, train acc 0.929, test acc 0.908, time 56.7 sec\nepoch 9, loss 0.0007, train acc 0.932, test acc 0.912, time 56.5 sec\nepoch 10, loss 0.0007, train acc 0.936, test acc 0.902, time 56.9 sec\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# First\n    train acc 0.948, test acc 0.917,\n    batch_size = 128\n    GPU_max = 56\n    time = 57\n# Second\n    train acc 0.917, test acc 0.900,\n    batch_size = 128\n    weight_decay = 0.01\n    GPU_max = 50\n    time = 57\n\n# Third\n    train acc 0.930, test acc 0.920,\n    batch_size = 128\n    weight_decay = 0.0001\n    GPU_max = 50\n    time = 57\n# four\n    train acc 0.936, test acc 0.902,\n    batch_size = 32\n    weight_decay = 0.0001\n    GPU_max = 58\n    time = 57\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 训练\nlr, num_epochs,weight_decay = 0.001, 10,0.0001\nnet = VGG()\ndef init_weights(m):\n    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n        torch.nn.init.xavier_uniform_(m.weight)\n\nnet.apply(init_weights)\nnet = net.to(device)\n\ncriterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\ntrain_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr,weight_decay)","execution_count":29,"outputs":[{"output_type":"stream","text":"training on cuda:0\nepoch 1, loss 0.0028, train acc 0.734, test acc 0.867, time 48.8 sec\nepoch 2, loss 0.0014, train acc 0.874, test acc 0.893, time 48.7 sec\nepoch 3, loss 0.0011, train acc 0.895, test acc 0.907, time 48.7 sec\nepoch 4, loss 0.0010, train acc 0.910, test acc 0.910, time 48.7 sec\nepoch 5, loss 0.0009, train acc 0.920, test acc 0.919, time 48.0 sec\nepoch 6, loss 0.0008, train acc 0.925, test acc 0.925, time 48.5 sec\nepoch 7, loss 0.0007, train acc 0.932, test acc 0.926, time 48.4 sec\nepoch 8, loss 0.0007, train acc 0.937, test acc 0.927, time 48.5 sec\nepoch 9, loss 0.0006, train acc 0.941, test acc 0.925, time 48.5 sec\nepoch 10, loss 0.0006, train acc 0.944, test acc 0.929, time 47.9 sec\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First\n    train acc 0.942, test acc 0.921,\n    batch_size = 32\n    weight_decay = 0.0001\n    GPU_max = 90\n    time = 52\n# second\n    train acc 0.944, test acc 0.929,\n    batch_size = 128\n    weight_decay = 0.0001\n    GPU_max = 90\n    time = 48"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 训练\nlr, num_epochs,weight_decay = 0.0001, 10,0.00001\nnet = NiN()\ndef init_weights(m):\n    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n        torch.nn.init.xavier_uniform_(m.weight)\n\nnet.apply(init_weights)\nnet = net.to(device)\n\ncriterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\ntrain_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr,weight_decay)","execution_count":37,"outputs":[{"output_type":"stream","text":"training on cuda:0\nepoch 1, loss 0.0071, train acc 0.372, test acc 0.574, time 47.8 sec\nepoch 2, loss 0.0042, train acc 0.629, test acc 0.679, time 47.4 sec\nepoch 3, loss 0.0035, train acc 0.688, test acc 0.700, time 47.9 sec\nepoch 4, loss 0.0032, train acc 0.709, test acc 0.728, time 47.4 sec\nepoch 5, loss 0.0030, train acc 0.729, test acc 0.735, time 47.7 sec\nepoch 6, loss 0.0028, train acc 0.740, test acc 0.739, time 47.5 sec\nepoch 7, loss 0.0027, train acc 0.748, test acc 0.753, time 46.9 sec\nepoch 8, loss 0.0026, train acc 0.758, test acc 0.761, time 47.9 sec\nepoch 9, loss 0.0025, train acc 0.762, test acc 0.768, time 47.8 sec\nepoch 10, loss 0.0025, train acc 0.767, test acc 0.772, time 48.2 sec\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First\n    train acc 0.864, test acc 0.860,\n    lr =0.001\n    batch_size = 128\n    weight_decay = 0.0001\n    GPU_max = 87\n    time = 48\n# Second\n    train acc 0.767, test acc 0.772,\n    lr = 0.01\n    batch_size = 128\n    weight_decay = 0.0001\n    GPU_max = 87\n    time = 48"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}