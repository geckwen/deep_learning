{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_csv.head()\n",
    "#train_csv.info()\n",
    "#train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_csv['label']\n",
    "train_csv.drop('label',axis =1, inplace =True)\n",
    "train_features = train_csv\n",
    "train_features = train_features.values.reshape(-1,1,28,28)\n",
    "train_labels = train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features.shape\n",
    "#train_labels.shape\n",
    "#train_labels[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 1, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv('test.csv')\n",
    "#test_csv.info()\n",
    "#test_csv.describe()\n",
    "#test_csv.head()\n",
    "test_features = test_csv.values.reshape(-1,1,28,28)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels, figsize=(12,12),size = 10):\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, size, figsize=figsize)\n",
    "    for f, i, j in zip(figs, range(size), range(size)):\n",
    "        f.imshow(images[i][0,:,:])\n",
    "        f.set_title(labels[j])\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(0.9,0.9))\n",
    "#plt.imshow(train_features[1][0,:,:],cmap='gray')\n",
    "#plt.show()\n",
    "#show_fashion_mnist(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size =256\n",
    "train_features = torch.tensor(train_features,dtype = torch.float)\n",
    "train_labels = torch.tensor(train_labels, dtype = torch.float)\n",
    "test_features = torch.tensor(test_features, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net\n",
    "class Flatten(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Reshape(torch.nn.Module): #将图像大小重定型\n",
    "    def forward(self, x):\n",
    "        return x.view(-1,1,28,28)      #(B x C x H x W)\n",
    "\n",
    "class digit_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(digit_net,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28\n",
    "            nn.Sigmoid(),                                                       \n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)                               #b*16*10*10  => b*16*5*5\n",
    "            )   \n",
    "        self.dense = nn.Sequential(                                                         #b*16*5*5   => b*400\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        return self.dense(self.conv(x).view(x.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n",
    "             legend=None, figsize=(3.5, 2.5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogy(x_vals, y_vals)\n",
    "    if x2_vals and y2_vals:\n",
    "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
    "        plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
    "    net.eval()\n",
    "    for X,y in data_iter:\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y.squeeze()))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features,train_labels, test_features, test_labels, \n",
    "                  num_epochs,batch_size,lr,weight_decay,criterion ):\n",
    "    optimizer = torch.optim.Adam(params = net.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    if test_features is not None:\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_features,test_labels)\n",
    "        test_iter = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle=True)\n",
    "    train_acc_sum = torch.tensor([0.0],dtype=torch.float32)\n",
    "    test_acc_sum = torch.tensor([0.0],dtype=torch.float32)\n",
    "    for i in range(num_epochs):\n",
    "        train_acc = torch.tensor([0.0],dtype=torch.float32)\n",
    "        n = 0\n",
    "        for x , y in train_iter:\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(x)\n",
    "            loss = criterion(y_hat, y.long())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_acc += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "        if test_features is not None:\n",
    "            test_acc = evaluate_accuracy(test_iter,net)\n",
    "            test_acc_sum += test_acc\n",
    "        train_acc_sum += train_acc/n\n",
    "    return train_acc_sum/num_epochs,test_acc_sum/num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold(i,k,train_features, train_labels):\n",
    "    fold_size = len(train_features)//k\n",
    "    features_train, labels_train = None,None\n",
    "    for j in range(k):\n",
    "        idx = slice(j*fold_size, (j+1)*fold_size)\n",
    "        features_part , labels_part = train_features[idx,:,:,:],train_labels[idx]\n",
    "        if i == j:\n",
    "            features_valid,labels_valid = features_part, labels_part\n",
    "        elif features_train is  None:\n",
    "            features_train, labels_train = features_part,labels_part\n",
    "        else :\n",
    "            features_train = torch.cat((features_train,features_part),dim =0 )\n",
    "            labels_train = torch.cat((labels_train, labels_part),dim = 0)\n",
    "    return features_train,labels_train, features_valid , labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, train_features, train_labels, num_epochs, lr , weight_decay,batch_size,criterion):\n",
    "    for i in range(k):\n",
    "        data = get_k_fold(i,k,train_features, train_labels)\n",
    "        train_l,test_l = train(net,*data,num_epochs,batch_size,lr,weight_decay,criterion)\n",
    "        train_l_sum += train_l[-1]\n",
    "        test_l_sum += test_l[-1]\n",
    "        if i == 0:\n",
    "            semilogy(range(1, num_epochs + 1), train_l, 'epochs', 'rmse',\n",
    "                         range(1, num_epochs + 1), test_l,\n",
    "                         ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_l[-1], test_l[-1]))\n",
    "    return train_l_sum/k, test_l_sum/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-653fe2af4453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigit_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d-fold validation: avg train rmse %f, avg valid rmse %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c035cde0d2c4>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size, criterion)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_k_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-040e0dc12274>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_features, train_labels, test_features, test_labels, num_epochs, batch_size, lr, weight_decay, criterion)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k, num_epochs, lr, weight_decay, batch_size ,drop_prob = 10, 100, 0.01, 0, 64,0.6\n",
    "net = digit_net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr , weight_decay,batch_size,criterion)\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f' % (k, train_l, valid_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
